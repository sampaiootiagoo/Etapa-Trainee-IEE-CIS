{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc65f4cb",
   "metadata": {},
   "source": [
    "# Aplicando as técnicas no conjunto de dados do MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade1a82a",
   "metadata": {},
   "source": [
    "## Importando o Dataset e fazendo manipulações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff67e70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.datasets\n",
    "from keras.datasets import mnist     # Dataset MNIST direto do Keras\n",
    "import numpy as np\n",
    "import random\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.utils import resample\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, RegressorMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils                         # Ferramentas relacionadas ao NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2575c83a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape (60000, 28, 28)\n",
      "y_train shape (60000,)\n",
      "X_test shape (10000, 28, 28)\n",
      "y_test shape (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Os dados do MNIST jávem separados em 60,000 imagens de treino (28x28 pixels) e 10,000 imagens para teste (28x28 pixels).\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data() # Separando os dados em treino e teste\n",
    "\n",
    "print(\"X_train shape\", X_train.shape)\n",
    "print(\"y_train shape\", y_train.shape)\n",
    "print(\"X_test shape\", X_test.shape)\n",
    "print(\"y_test shape\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65835105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training matrix shape (60000, 784)\n",
      "Testing matrix shape (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(60000, 784) # remodelar(reshape) 60.000 matrizes 28 x 28 em 60.000 vetores de comprimento de 784.\n",
    "X_test = X_test.reshape(10000, 784)   # remodelar(reshape) 10.000 matrizes 28 x 28 em 10.000 vetores de comprimento de 784.\n",
    "\n",
    "X_train = X_train.astype('float32')   # alterando para ponto flutuante (float) de 32 bits\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train /= 255          # máximo valor de um pixel (normalização)\n",
    "X_test /= 255\n",
    "\n",
    "print(\"Training matrix shape\", X_train.shape)\n",
    "print(\"Testing matrix shape\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "658d80c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10 # número de dígitos únicos\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, n_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c1fe2a",
   "metadata": {},
   "source": [
    "## Perceptron Multicamada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d08ed7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerPerceptron(BaseEstimator, ClassifierMixin): \n",
    "    def __init__(self, params=None):     \n",
    "        if (params == None):\n",
    "            self.inputLayer = 30                        # Camada de Input\n",
    "            self.hiddenLayer = 1                       # Camadas Ocultas\n",
    "            self.OutputLayer = 10                       # Camadas de Output\n",
    "            self.learningRate = 0.005                  # Taxa de aprendizado\n",
    "            self.max_epochs = 600                      # Épocas\n",
    "            self.BiasHiddenValue = -1                   # Bias das Camadas Ocultas\n",
    "            self.BiasOutputValue = -1                  # Bias da Camada de Output\n",
    "            self.activation = self.ativacao['sigmoid'] # Função de Ativação\n",
    "            self.deriv = self.derivada['sigmoid']\n",
    "        else:\n",
    "            self.inputLayer = params['InputLayer']\n",
    "            self.hiddenLayer = params['HiddenLayer']\n",
    "            self.OutputLayer = params['OutputLayer']\n",
    "            self.learningRate = params['LearningRate']\n",
    "            self.max_epochs = params['Epocas']\n",
    "            self.BiasHiddenValue = params['BiasHiddenValue']\n",
    "            self.BiasOutputValue = params['BiasOutputValue']\n",
    "            self.activation = self.ativacao[params['ActivationFunction']]\n",
    "            self.deriv = self.derivada[params['ActivationFunction']]\n",
    "        \n",
    "        'Iniciando pesos e bias aleatoriamente'\n",
    "        self.WEIGHT_hidden = self.starting_weights(self.hiddenLayer, self.inputLayer)\n",
    "        self.WEIGHT_output = self.starting_weights(self.OutputLayer, self.hiddenLayer)\n",
    "        self.BIAS_hidden = np.array([self.BiasHiddenValue for i in range(self.hiddenLayer)])\n",
    "        self.BIAS_output = np.array([self.BiasOutputValue for i in range(self.OutputLayer)])\n",
    "        self.classes_number = 10 \n",
    "        \n",
    "    pass\n",
    "    \n",
    "    def starting_weights(self, x, y):\n",
    "        return [[2  * random.random() - 1 for i in range(x)] for j in range(y)]\n",
    "\n",
    "    ativacao = {\n",
    "         'sigmoid': (lambda x: 1/(1 + np.exp(-x))),\n",
    "            'tanh': (lambda x: np.tanh(x)),\n",
    "            'Relu': (lambda x: x*(x > 0)),\n",
    "               }\n",
    "    derivada = {\n",
    "         'sigmoid': (lambda x: x*(1-x)),\n",
    "            'tanh': (lambda x: 1-x**2),\n",
    "            'Relu': (lambda x: 1 * (x>0))\n",
    "               }\n",
    " \n",
    "    def Backpropagation_Algorithm(self, x):\n",
    "        DELTA_output = []\n",
    "        'Fase 1 - Erro: OutputLayer'\n",
    "        ERROR_output = self.output - self.OUTPUT_L2\n",
    "        DELTA_output = ((-1)*(ERROR_output) * self.deriv(self.OUTPUT_L2))\n",
    "        \n",
    "        arrayStore = []\n",
    "        'Fase 2 - Atualizando pesos da OutputLayer e HiddenLayer'\n",
    "        for i in range(self.hiddenLayer):\n",
    "            for j in range(self.OutputLayer):\n",
    "                self.WEIGHT_output[i][j] -= (self.learningRate * (DELTA_output[j] * self.OUTPUT_L1[i]))\n",
    "                self.BIAS_output[j] -= (self.learningRate * DELTA_output[j])\n",
    "      \n",
    "        'Fase 3 - Erro: HiddenLayer'\n",
    "        delta_hidden = np.matmul(self.WEIGHT_output, DELTA_output)* self.deriv(self.OUTPUT_L1)\n",
    " \n",
    "        'Fase 4 - Atualizando pesos da HiddenLayer e InputLayer(x)'\n",
    "        for i in range(self.OutputLayer):\n",
    "            for j in range(self.hiddenLayer):\n",
    "                self.WEIGHT_hidden[i][j] -= (self.learningRate * (delta_hidden[j] * x[i]))\n",
    "                self.BIAS_hidden[j] -= (self.learningRate * delta_hidden[j])\n",
    "                \n",
    " #   def show_err_graphic(self,v_erro,v_epoca):\n",
    " #       plt.figure(figsize=(9,4))\n",
    " #       plt.plot(v_epoca, v_erro, \"m-\",color=\"b\", marker=11)\n",
    " #       plt.xlabel(\"Number of Epochs\")\n",
    " #       plt.ylabel(\"Squared error (MSE) \");\n",
    " #       plt.title(\"Error Minimization\")\n",
    " #       plt.show()\n",
    "\n",
    "    def predict(self, X, y):\n",
    "        'Retorna a predição pra cada valor de X'\n",
    "        my_predictions = []\n",
    "        'Algoritmo Forward'\n",
    "        forward = np.matmul(X,self.WEIGHT_hidden) + self.BIAS_hidden\n",
    "        forward = np.matmul(forward, self.WEIGHT_output) + self.BIAS_output\n",
    "                                 \n",
    "        for i in forward:\n",
    "            my_predictions.append(max(enumerate(i), key=lambda x:x[1])[0])\n",
    "            \n",
    "        array_score = []\n",
    "        for i in range(len(my_predictions)):\n",
    "            if my_predictions[i] == 0: \n",
    "                array_score.append([i, 'Zero', my_predictions[i], y[i]])\n",
    "            elif my_predictions[i] == 1:\n",
    "                 array_score.append([i, 'Um', my_predictions[i], y[i]])\n",
    "            if my_predictions[i] == 2: \n",
    "                array_score.append([i, 'Dois', my_predictions[i], y[i]])\n",
    "            elif my_predictions[i] == 3:\n",
    "                 array_score.append([i, 'Três', my_predictions[i], y[i]])\n",
    "            if my_predictions[i] == 4: \n",
    "                array_score.append([i, 'Quatro', my_predictions[i], y[i]])\n",
    "            elif my_predictions[i] == 5:\n",
    "                 array_score.append([i, 'Cinco', my_predictions[i], y[i]])\n",
    "            if my_predictions[i] == 6: \n",
    "                array_score.append([i, 'Seis', my_predictions[i], y[i]])\n",
    "            elif my_predictions[i] == 7:\n",
    "                 array_score.append([i, 'Sete', my_predictions[i], y[i]])\n",
    "            if my_predictions[i] == 8: \n",
    "                array_score.append([i, 'Oito', my_predictions[i], y[i]])\n",
    "            elif my_predictions[i] == 9:\n",
    "                 array_score.append([i, 'Nove', my_predictions[i], y[i]])\n",
    "                    \n",
    "        dataframe = pd.DataFrame(array_score, columns=['_id', 'class', 'output', 'hoped_output'])\n",
    "        return my_predictions, dataframe\n",
    "\n",
    "    def fit(self, X, y):  \n",
    "        count_epoch = 1\n",
    "        total_error = 0\n",
    "        n = len(X); \n",
    "        epoch_array = []\n",
    "        error_array = []\n",
    "        W0 = []\n",
    "        W1 = []\n",
    "        while(count_epoch <= self.max_epochs):\n",
    "            for idx,inputs in enumerate(X): \n",
    "                self.output = np.zeros(self.classes_number)\n",
    "                'Fase 1 - (Algoritmo Forward)'\n",
    "                self.OUTPUT_L1 = self.activation((np.dot(inputs, self.WEIGHT_hidden) + self.BIAS_hidden.T))\n",
    "                self.OUTPUT_L2 = self.activation((np.dot(self.OUTPUT_L1, self.WEIGHT_output) + self.BIAS_output.T))\n",
    "                'Fase 2 - One-Hot-Encoding'\n",
    "                if(y.any() == 0): \n",
    "                    self.output = np.array([1,0,0,0,0,0,0,0,0,0])\n",
    "                elif(y.any() == 1):\n",
    "                    self.output = np.array([0,1,0,0,0,0,0,0,0,0]) \n",
    "                if(y.any() == 2): \n",
    "                    self.output = np.array([0,0,1,0,0,0,0,0,0,0])\n",
    "                elif(y.any() == 3):\n",
    "                    self.output = np.array([0,0,0,1,0,0,0,0,0,0]) \n",
    "                if(y.any() == 4): \n",
    "                    self.output = np.array([0,0,0,0,1,0,0,0,0,0])\n",
    "                elif(y.any() == 5):\n",
    "                    self.output = np.array([0,0,0,0,0,1,0,0,0,0]) \n",
    "                if(y.any() == 6): \n",
    "                    self.output = np.array([0,0,0,0,0,0,1,0,0,0])\n",
    "                elif(y.any() == 7):\n",
    "                    self.output = np.array([0,0,0,0,0,0,0,1,0,0]) \n",
    "                if(y.any() == 8): \n",
    "                    self.output = np.array([0,0,0,0,0,0,0,0,1,0])\n",
    "                elif(y.any() == 9):\n",
    "                    self.output = np.array([0,0,0,0,0,0,0,0,0,1]) \n",
    "\n",
    "                \n",
    "                square_error = 0\n",
    "                for i in range(self.OutputLayer):\n",
    "                    erro = (self.output[i] - self.OUTPUT_L2[i])**2\n",
    "                    square_error = (square_error + (0.05 * erro))\n",
    "                    total_error = total_error + square_error\n",
    "         \n",
    "                'Backpropagation : Atualização de pesos'\n",
    "                self.Backpropagation_Algorithm(inputs)\n",
    "                \n",
    "            total_error = (total_error / n)\n",
    "            if((count_epoch % 10 == 0)or(count_epoch == 1)):\n",
    "                print(\"Época \", count_epoch, \"- Erro Total: \",total_error, f'\\n Acurácia: {round((1-total_error)*100,2)}%')\n",
    "                error_array.append(total_error)\n",
    "                epoch_array.append(count_epoch)\n",
    "                \n",
    "            W0.append(self.WEIGHT_hidden)\n",
    "            W1.append(self.WEIGHT_output)\n",
    "             \n",
    "                \n",
    "            count_epoch += 1\n",
    "#        self.show_err_graphic(error_array,epoch_array)\n",
    "        \n",
    "#        plt.plot(W0[0])\n",
    "#        plt.title('Weight Hidden update during training')\n",
    "#        plt.legend(['neuron1', 'neuron2', 'neuron3', 'neuron4', 'neuron5'])\n",
    "#        plt.ylabel('Value Weight')\n",
    "#        plt.show()\n",
    "        \n",
    "#        plt.plot(W1[0])\n",
    "#        plt.title('Weight Output update during training')\n",
    "#        plt.legend(['neuron1', 'neuron2', 'neuron3'])\n",
    "#        plt.ylabel('Value Weight')\n",
    "#        plt.show()\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fa883a",
   "metadata": {},
   "source": [
    "## Testando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5bb2c484",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acuracia(y_true, y_pred):\n",
    "    acuracia = np.sum(y_true == y_pred) / len(y_true)\n",
    "    return acuracia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c5d30ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época  1 - Erro Total:  0.045242697606371195 \n",
      " Acurácia: 95.48%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-cdc178b783a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mPerceptron\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMultiLayerPerceptron\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mPerceptron\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#import warnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-625126b39f16>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    140\u001b[0m                 \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m                 \u001b[1;32melif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m                 \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_any\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;31m# Parsing keyword arguments is currently fairly slow, so avoid it for now\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mwhere\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mumr_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mumr_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dic = {'InputLayer':784, 'HiddenLayer':1, 'OutputLayer':10,\n",
    "              'Epocas':10, 'LearningRate':0.01,'BiasHiddenValue':-1, \n",
    "              'BiasOutputValue':-1, 'ActivationFunction':'tanh'}\n",
    "\n",
    "Perceptron = MultiLayerPerceptron(dic)\n",
    "Perceptron.fit(X_train,Y_train)\n",
    "\n",
    "#import warnings\n",
    "#warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a720c4",
   "metadata": {},
   "source": [
    "Mesmo com somente 10 épocas, o tempo de execução foi extremamente alto, o que acabou começando a comprometer o meu computador, então a execução foi parada. Não se sabe quantas épocas foram feitas, sabe-se que foi algo entre 1 e 9 épocas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
